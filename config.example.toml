[logging]
enabled = true
level = "info"
format = "json"

[logging.conversation_logging]
# Enable logging of full conversations to file
enabled = true
# File path for conversation logs (relative to working directory or absolute)
file_path = "/tmp/conversations.log"
# Include system messages in the logged conversations
include_system_messages = true
# Include timestamps in the logged conversations
include_timestamps = true

[server]
port = 3000
host = "localhost"

[server.cors]
enabled = true
origins = ["*"]

[[models]]
id = "claude-3-5-sonnet-20241022"
display_name = "Claude 3.5 Sonnet"
provider = "openai"

[models.config]
base_url = "https://api.openai.com"
api_key = "sk-your-openai-key-here"
model_name = "gpt-4o"

[[models]]
id = "claude-3-opus-20240229"
display_name = "Claude 3 Opus"
provider = "openai"

[models.config]
base_url = "https://api.openai.com"
api_key = "sk-your-openai-key-here"
model_name = "gpt-4"

[[models]]
id = "claude-3-haiku-20240307"
display_name = "Claude 3 Haiku"
provider = "openai"

[models.config]
base_url = "https://api.openai.com"
api_key = "sk-your-openai-key-here"
model_name = "gpt-4o-mini"

[[models]]
id = "claude-3-5-sonnet-20241022-groq"
display_name = "Claude 3.5 Sonnet (Groq)"
provider = "groq"

[models.config]
base_url = "https://api.groq.com/openai"
api_key = "gsk_your_groq_key_here"
model_name = "llama-3.1-70b-versatile"

[model_routing]
# Default model ID - set this to one of your configured model IDs
default_model_id = "claude-3-5-sonnet-20241022"
# Route claude-* model requests to default when not found (default: true)
route_claude_models_to_default = true

[defaults]
model = "claude-3-5-sonnet-20241022"  # Deprecated - use model_routing.default_model_id instead
max_tokens = 4096
temperature = 0.7
stream = false

[rate_limits]
requests_per_minute = 60
tokens_per_minute = 100000

[cache]
enabled = false
ttl = 300
max_size = 1000